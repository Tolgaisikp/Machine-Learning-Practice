{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doğrusal regresyon. Bir bölgedeki ortalama sıcaklığa, yağışa ve neme (girdi değişkenleri veya özellikler) bakarak elma ve portakal için mahsul verimini (hedef değişkenler) tahmin eden bir model oluşturacağız. İşte eğitim verileri:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://i.imgur.com/6Ujttb4.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73.,  67.,  43.],\n",
       "       [ 91.,  88.,  64.],\n",
       "       [ 87., 134.,  58.],\n",
       "       [102.,  43.,  37.],\n",
       "       [ 69.,  96.,  70.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputs (temp, rainfall and humidity)\n",
    "inputs = np.array([[73,67,43],\n",
    "                  [91,88,64],\n",
    "                  [87,134,58],\n",
    "                  [102,43,37],\n",
    "                  [69,96,70]], dtype = 'float32')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.,  70.],\n",
       "       [ 81., 101.],\n",
       "       [119., 133.],\n",
       "       [ 22.,  37.],\n",
       "       [103., 119.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets (apple and oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype = 'float32')\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Girişleri ve hedefleri tensörlere dönüştürün\n",
    "inputs = t.from_numpy(inputs)\n",
    "targets = t.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model from scratch (Sıfırdan doğrusal regresyon modeli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1693,  0.2874,  1.6815],\n",
      "        [-0.0786,  0.7411, -0.9778]], requires_grad=True)\n",
      "tensor([-1.3982,  0.0665], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases (bu değerler başlangıçta random değer olmasından dolayı random fonk kullanılır)\n",
    "w = t.randn(2, 3, requires_grad = True)\n",
    "b = t.randn(2, requires_grad  = True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch.randn, ortalama 0 ve standart sapma 1 ile normal bir dağılımdan rastgele seçilen elemanlarla, verilen şekle sahip bir tensör oluşturur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b \n",
    "#tranposesini alma nedeni matrsi boylarını eşitleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'@' PyTorch'ta matris çarpımını temsil eder ve '.t()' yöntemi bir tensörün tranposesini döndürür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[102.5267,   1.9359],\n",
       "        [146.9228,  -4.4504],\n",
       "        [149.3777,  35.8219],\n",
       "        [ 90.4502, -12.2627],\n",
       "        [155.5859,  -2.6596]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimizin tahminlerini gerçek hedeflerle karşılaştıralım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimizin tahminleri ile gerçek hedefler arasında büyük bir fark görebilirsiniz çünkü modelimizi rastgele ağırlıklar ve önyargılar ile başlattık. Açıkçası, rastgele başlatılmış bir modelin sadece çalışmasını bekleyemeyiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Modelimizi geliştirmeden önce, modelimizin ne kadar iyi performans gösterdiğini değerlendirmenin bir yoluna ihtiyacımız var. Aşağıdaki yöntemi kullanarak modelin tahminlerini gerçek hedeflerle karşılaştırabiliriz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*İki matris (ön ve hedefler) arasındaki farkı hesaplayın.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Negatif değerleri kaldırmak için fark matrisinin tüm öğelerinin karesini alın.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ortaya çıkan matristeki elemanların ortalamasını hesaplayın.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonuç, ortalama hata karesi (MSE) olarak bilinen tek bir sayıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return t.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diff.sum(), bir tensördeki tüm öğelerin toplamını döndürür. Bir tensörün diff.numel() yöntemi, tensördeki öğelerin sayısını (miktarını) döndürür. Modelimizin mevcut tahminleri için ortalama hata karesini hesaplayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5730.8018, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonucu şu şekilde yorumlayabiliriz: Ortalama olarak, tahmindeki her bir öğe, kaybın kareköküne göre gerçek hedeften farklıdır. Ve tahmin etmeye çalıştığımız sayıların kendilerinin 50–200 aralığında olduğunu düşünürsek, bu oldukça kötü. Sonuç, modelin hedef değişkenleri tahmin etmede ne kadar kötü olduğunu gösterdiği için kayıp olarak adlandırılır. Modeldeki bilgi kaybını temsil eder: kayıp ne kadar düşükse model o kadar iyidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degradeler, ilgili tensörlerin .grad özelliğinde saklanır. Kaybın türevi w.r.t. Ağırlık matrisinin kendisi aynı boyutlara sahip bir matristir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1693,  0.2874,  1.6815],\n",
      "        [-0.0786,  0.7411, -0.9778]], requires_grad=True)\n",
      "tensor([[ 4529.7266,  4196.1421,  2839.0566],\n",
      "        [-7287.6943, -8131.8828, -5130.1611]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust weights and biases to reduce the loss (Kaybı azaltmak için ağırlıkları ve önyargıları ayarlayın)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kayıp, ağırlıklarımızın ve önyargılarımızın ikinci dereceden bir fonksiyonudur ve amacımız, kaybın en düşük olduğu ağırlık setini bulmaktır. Herhangi bir ağırlık veya önyargı unsuru ile kayıp grafiğini çizersek, aşağıda gösterilen şekle benzeyecektir. Analizden elde edilen önemli bir kavrayış, gradyanın, kaybın değişim oranını, yani kayıp fonksiyonunun eğimini w.r.t gösterdiğidir. Ağırlıklar ve önyargılar.\n",
    "\n",
    "Bir gradyan öğesi pozitifse:\n",
    "\n",
    "--Ağırlık elemanının değerini biraz arttırmak kaybı artıracaktır\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Ağırlık elemanının değerini biraz azaltmak kaybı azaltacaktır"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir gradyan öğesi negatifse:\n",
    "\n",
    "--Ağırlık elemanının değerini biraz arttırmak kaybı azaltacaktır\n",
    "\n",
    "--Ağırlık elemanının değerini biraz azaltmak, kaybı artıracaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir ağırlık elemanının değiştirilmesiyle kayıptaki artış veya azalma, kayıp w.r.t. ile orantılıdır. Bu öğe. Bu gözlem, modelimizi geliştirmek için kullanacağımız gradyan iniş optimizasyon algoritmasının temelini oluşturur (gradyan boyunca inerek).\n",
    "\n",
    "Her ağırlık elemanından kaybın w.r.t türevine orantılı küçük bir miktar çıkarabiliriz. Kaybı biraz azaltmak için bu unsur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4529.7266,  4196.1421,  2839.0566],\n",
       "        [-7287.6943, -8131.8828, -5130.1611]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ağırlıkları çok büyük miktarda değiştirmememiz için gradyanları çok küçük bir sayı (bu durumda 10 ~ -5) ile çarpıyoruz. Eğimin yokuş aşağı yönünde küçük bir adım atmak istiyoruz, dev bir sıçrama değil. Bu sayı, algoritmanın öğrenme hızı olarak adlandırılır.\n",
    "\n",
    "1e-5 bizim öğrenme hızımızdır\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t.no_grad'ı PyTorch'a ağırlıkları ve biasları güncellerken degradeleri izlemememiz, hesaplamamamız veya değiştirmememiz gerektiğini belirtmek için kullanıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t.no_grad()\n",
    "Gradyan hesaplamasını devre dışı bırakan bağlam yöneticisi.\n",
    "\n",
    "Gradyan hesaplamasını devre dışı bırakmak, Tensor.backward () 'ı çağırmayacağınızdan emin olduğunuzda çıkarım için kullanışlıdır. Aksi takdirde require_grad = True olacak olan hesaplamalar için bellek tüketimini azaltacaktır.\n",
    "\n",
    "Bu modda, girişler require_grad = True olsa bile, her hesaplamanın sonucu, require_grad = False olacaktır.\n",
    "\n",
    "Bu bağlam yöneticisi iş parçacığı yereldir; Diğer iş parçacıklarındaki hesaplamayı etkilemeyecektir.\n",
    "\n",
    "Aynı zamanda bir dekoratör olarak da işlev görür. (Parantez ile somutlaştırdığınızdan emin olun.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5 \n",
    "#backward ile gradyan fonksiyonun tanımını engellemek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5730.8018, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Kaybın aslında daha düşük olduğunu doğrulayalım\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devam etmeden önce, .zero_ () yöntemini çağırarak degradeleri sıfırlıyoruz. Bunu yapmamız gerekiyor çünkü PyTorch gradyanları biriktiriyor. Aksi takdirde, kayıpta .backward'ı bir dahaki sefere çağırdığımızda, yeni gradyan değerleri mevcut gradyanlara eklenir ve bu da beklenmedik sonuçlara yol açabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient descent kullanarak modeli eğitin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3773.5383,  3388.0063,  2339.2969],\n",
      "        [-5947.4214, -6690.0952, -4240.6602]])\n",
      "tensor([ 43.8127, -72.4196])\n",
      "tensor([[ 0.0863,  0.2116,  1.6297],\n",
      "        [ 0.0538,  0.8893, -0.8841]], requires_grad=True)\n",
      "tensor([-1.3992,  0.0681], requires_grad=True)\n",
      "tensor(2807.1777, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#1 Generate predictions\n",
    "preds = model(inputs)\n",
    "#2 Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "#3 Compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)\n",
    "#4 Adjust weights & reset gradients\n",
    "with t.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "print(w)\n",
    "print(b)\n",
    "\n",
    "#last calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitim için birden çok epoch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaybı daha da azaltmak için, gradyanları birden çok kez kullanarak ağırlıkları ve önyargıları ayarlama işlemini tekrarlayabiliriz. Her yinelemeye epoch denir. Modeli eğitmek için 100 epoch yapalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(208.7466, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with t.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "#Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 59.1401,  73.0487],\n",
       "        [ 90.6590,  90.9539],\n",
       "        [ 96.2910, 150.6521],\n",
       "        [ 34.6419,  51.7038],\n",
       "        [108.4341,  93.6772]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using PyTorch built-ins (PyTorch fonksiyonlarını kullanarak lineer regresyon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Bazı temel tensör işlemlerini kullanarak doğrusal regresyon ve gradyan iniş modeli uyguladık. Bununla birlikte, bu derin öğrenmede yaygın bir model olduğundan, PyTorch, sadece birkaç satır kodla modeller oluşturmayı ve eğitmeyi kolaylaştırmak için çeşitli yerleşik işlevler ve sınıflar sağlar.\n",
    "\n",
    "Sinir ağları oluşturmak için yardımcı sınıflar içeren PyTorch'tan torch.nn paketini içe aktararak başlayalım.\n",
    "\n",
    "nn (neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = t.from_numpy(inputs)\n",
    "targets = t.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.],\n",
       "        [ 74.,  66.,  43.],\n",
       "        [ 91.,  87.,  65.],\n",
       "        [ 88., 134.,  59.],\n",
       "        [101.,  44.,  37.],\n",
       "        [ 68.,  96.,  71.],\n",
       "        [ 73.,  66.,  44.],\n",
       "        [ 92.,  87.,  64.],\n",
       "        [ 87., 135.,  57.],\n",
       "        [103.,  43.,  36.],\n",
       "        [ 68.,  97.,  70.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Girişlerden ve hedeflerden gelen satırlara tuple olarak erişime izin veren ve PyTorch'daki birçok farklı veri kümesiyle çalışmak için standart API'ler sağlayan bir TensorDataset oluşturacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayrıca, eğitim sırasında verileri önceden tanımlanmış boyutta toplu işlere ayırabilen bir Veri Yükleyici de oluşturacağız. Ayrıca verilerin karıştırılması ve rastgele örneklenmesi gibi başka yardımcı programlar da sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)# shuffle = karıştırma --- batch_size = yığın boyutu\n",
    "#karıştırılıp rastgele örneklemler oluşturur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 68.,  97.,  70.],\n",
      "        [103.,  43.,  36.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 73.,  66.,  44.],\n",
      "        [ 91.,  88.,  64.]])\n",
      "tensor([[102., 120.],\n",
      "        [ 20.,  38.],\n",
      "        [119., 133.],\n",
      "        [ 57.,  69.],\n",
      "        [ 81., 101.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her yinelemede, veri yükleyici, verilen toplu iş boyutuna sahip bir veri grubu döndürür. Karıştırma True olarak ayarlanmışsa, gruplar oluşturmadan önce eğitim verilerini karıştırır. Karıştırma, girdiyi optimizasyon algoritmasına rastgele hale getirmeye yardımcı olarak kayıpta daha hızlı bir azalmaya yol açar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ağırlıkları ve biasları manuel olarak başlatmak yerine, modeli otomatik olarak yapan PyTorch'un nn.Linear sınıfını kullanarak tanımlayabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2446,  0.3400,  0.5594],\n",
      "        [ 0.4791,  0.4821,  0.3623]], requires_grad=True)\n",
      "---------------------------------------------------------\n",
      "Parameter containing:\n",
      "tensor([ 0.1449, -0.5750], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3,2) #3x2 lik matris 3 input 2 output\n",
    "print(model.weight)\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch modelleri, modelde bulunan tüm ağırlıkları ve bias matrislerini içeren bir liste döndüren yararlı bir .parameters yöntemine de sahiptir. Doğrusal regresyon modelimiz için, bir ağırlık matrisimiz ve bir bias matrisimiz var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2446,  0.3400,  0.5594],\n",
       "         [ 0.4791,  0.4821,  0.3623]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1449, -0.5750], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 29.1250,  82.2766],\n",
       "        [ 43.6105, 108.6316],\n",
       "        [ 56.8725, 126.7164],\n",
       "        [ 10.5149,  82.4283],\n",
       "        [ 55.0683, 104.1208],\n",
       "        [ 28.5404,  82.2737],\n",
       "        [ 43.8299, 108.5118],\n",
       "        [ 57.1874, 127.5578],\n",
       "        [ 11.0995,  82.4312],\n",
       "        [ 55.8724, 104.0039],\n",
       "        [ 29.3445,  82.1568],\n",
       "        [ 43.0259, 108.6287],\n",
       "        [ 56.6531, 126.8363],\n",
       "        [  9.7109,  82.5451],\n",
       "        [ 55.6529, 104.1237]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir kayıp fonksiyonunu manuel olarak tanımlamak yerine, yerleşik kayıp fonksiyonu mse_loss kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1080.6128, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = F.mse_loss\n",
    "loss = loss_fn(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin ağırlıklarını ve biaslarını gradyanlar kullanarak manuel olarak değiştirmek yerine, optimize edici optim.SGD()'yi kullanabiliriz. SGD, 'stokastik gradyan iniş' in kısaltmasıdır. Stokastik terimi, numunelerin tek bir grup yerine rastgele gruplar halinde seçildiğini belirtir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2446,  0.3400,  0.5594],\n",
       "         [ 0.4791,  0.4821,  0.3623]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1449, -0.5750], requires_grad=True)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = t.optim.SGD(model.parameters(), lr = 1e-5)#ilk olarak model içindeki weigth ve bias değerlerini yollar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model.parameters () öğesinin optim.SGD'ye bir argüman olarak aktarıldığını ve böylece optimize edicinin güncelleme adımı sırasında hangi matrislerin değiştirilmesi gerektiğini bildiğine dikkat edin. Ayrıca, parametrelerin değiştirilme miktarını kontrol eden bir öğrenme oranı belirleyebiliriz.\n",
    "\n",
    "lr = 1e-5 => öğrenme parametresi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the model. We'll follow the same process to implement gradient descent:\n",
    "\n",
    "1--Generate predictions\n",
    "\n",
    "2--Calculate the loss\n",
    "\n",
    "3--Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4--Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5--Reset the gradients to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tek değişiklik, her yinelemede tüm eğitim verilerini işlemek yerine veri yığınları üzerinde çalışacağımızdır. Modeli belirli sayıda dönem için eğiten bir fayda işlevi uyumu tanımlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(num_epochs, model, loss_fonc, opt, train_ld):\n",
    "    #epoch sayımızı fonktan alıyoruz\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Toplu veri ile eğitim (daha çok dersteki iterasyon tarzı)\n",
    "        for xb,yb in train_ld:\n",
    "        \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate Loss\n",
    "            loss = loss_fonc(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            #bu işlem bizim elle yaptığımız güncelleme işlemi tek satırda weight ve biasları güncellememizi sağlar \n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "            #teker teker w b'leri sıfırlamak yerine optimizer ile tek komutla sıfırladık\n",
    "        \n",
    "        if(epoch + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Parametreleri (ağırlıklar ve önyargılar) manuel olarak güncellemek yerine, güncellemeyi gerçekleştirmek için opt.step'i ve degradeleri sıfırlamak için opt.zero_grad'ı kullanırız.\n",
    "\n",
    "-Ayrıca, eğitimin ilerlemesini izlemek için her 10. çağ için son veri grubundaki kaybı yazdıran bir günlük ifadesi ekledik. Loss.item, kayıp tensöründe saklanan gerçek değeri döndürür"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/460], Loss: 76.3449\n",
      "Epoch [20/460], Loss: 170.0239\n",
      "Epoch [30/460], Loss: 85.3994\n",
      "Epoch [40/460], Loss: 33.1973\n",
      "Epoch [50/460], Loss: 54.9160\n",
      "Epoch [60/460], Loss: 50.6898\n",
      "Epoch [70/460], Loss: 16.4400\n",
      "Epoch [80/460], Loss: 17.9817\n",
      "Epoch [90/460], Loss: 24.3675\n",
      "Epoch [100/460], Loss: 15.4751\n",
      "Epoch [110/460], Loss: 8.2939\n",
      "Epoch [120/460], Loss: 13.2757\n",
      "Epoch [130/460], Loss: 11.7897\n",
      "Epoch [140/460], Loss: 7.1168\n",
      "Epoch [150/460], Loss: 9.5425\n",
      "Epoch [160/460], Loss: 7.4617\n",
      "Epoch [170/460], Loss: 5.1572\n",
      "Epoch [180/460], Loss: 4.3566\n",
      "Epoch [190/460], Loss: 3.2151\n",
      "Epoch [200/460], Loss: 7.1410\n",
      "Epoch [210/460], Loss: 5.1523\n"
     ]
    }
   ],
   "source": [
    "fit(460, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimizi kullanarak tahminler oluşturalım ve hedeflerimize yakın olduklarını doğrulayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nitekim tahminler hedeflerimize oldukça yakın. Bir bölgedeki ortalama sıcaklık, yağış ve neme bakarak elma ve portakal için mahsul verimini tahmin etmek için oldukça iyi bir model eğittik. Tek bir girdi satırı içeren bir grup geçirerek yeni bölgeler için mahsul verimi tahminlerinde bulunmak için kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(t.tensor([[75., 63., 44.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öngörülen elma verimi hektar başına 55,4 ton ve portakalınki hektar başına 68,7 tondur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning vs. Classical Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu eğitimde benimsediğimiz yaklaşım, bildiğiniz gibi programlamadan çok farklıdır. Genellikle, bazı girdiler alan, bazı işlemler gerçekleştiren ve sonuç veren programlar yazıyoruz.\n",
    "\n",
    "Bununla birlikte, bu defterde, bazı bilinmeyen parametreler (ağırlıklar ve önyargılar) kullanılarak ifade edilen, girdiler ve çıktılar arasında belirli bir ilişki olduğunu varsayan bir 'model' tanımladık. Daha sonra modeli bazı tanıdık girdi ve çıktıları gösterir ve modeli bilinmeyen parametreler için iyi değerler üretecek şekilde eğitiriz. Eğitildikten sonra, model yeni girdiler için çıktıları hesaplamak için kullanılabilir.\n",
    "\n",
    "Bu programlama paradigması, girdiler ve çıktılar arasındaki ilişkiyi anlamak için verileri kullandığımız makine öğrenimi olarak bilinir. Derin öğrenme, modeller oluşturmak ve eğitmek için matris işlemlerini, doğrusal olmayan etkinleştirme işlevlerini ve gradyan inişini kullanan bir makine öğrenimi dalıdır. Tesla Motors'ta AI direktörü Andrej Karpathy, bu konularda Software 2.0 başlıklı harika bir blog yazısı yazdı.\n",
    "\n",
    "Francois Chollet'in Python ile Derin Öğrenme kitabından bu resim, klasik programlama ile makine öğrenimi arasındaki farkı yakalıyor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Doğrusal regresyon yerine ileri beslemeli bir sinir ağı kullanmak için, nn.Module sınıfını PyTorch'tan genişletebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian\n",
    "jovian.commit(project='02-linear-regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}